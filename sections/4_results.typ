= Results

This section presents empirical findings from both stages of the analysis. We examine first the volume geographic distribution of legal review moderation actions across EU member states using data from the DSA Transparency Database, testing whether Germany exhibits disproportionate moderation activity consistent with systematic suppression (H1). Then, we analyze removal success rates using complaint-level data from the Lumen Database, testing whether businesses can reliably expect their takedown requests to succeed (H2).

== Volume and Geographic Distribution of Legal Actions

@by-source-type presented the distribution of Google Maps moderation actions by source type for the study period (June 1 – October 20, 2025). Of 24.6 million total actions, 23.0 million (93.82%) were voluntary actions under Google's internal content policies. Article 16 cases, moderation actions initiated through external legal complaints invoking national law, represent 1,515,000 actions (6.17% of total). @jur-composition demonstrates that voluntary actions apply uniformly across jurisdictions: 99.25% of voluntary actions are implemented EU-wide, reflecting Google's standardized content policies that operate identically regardless of geography @google_prohibited_2025. This uniformity makes voluntary actions unsuitable for examining cross-country variation in suppressive reputation management; any geographic differences in total moderation activity must therefore originate from the Article 16 category, where national legal frameworks govern platform obligations.

While numerically smaller, Article 16 cases exhibit substantial cross-country variation in how businesses leverage legal mechanisms to contest platform content. Table 2 shows that only 0.08% (1,229) of Article 16 actions apply EU-wide, while the overwhelming majority target specific national jurisdictions. This jurisdictional targeting makes Article 16 the primary focus of this analysis.

@mod-actions-by-cat disaggregates Article 16 actions by stated legal basis. Illegal or harmful speech accounts for 1,513,139 actions (99.88% of Article 16 total). Intellectual property infringement (1,772 actions, 0.12%), data protection violations (29 actions, \<0.01%), and other legal bases appear only marginally. This concentration indicates that defamation-based personality rights claims, rather than copyright or privacy concerns, drive the overwhelming majority of legally-prompted content actions on Google Maps. 

Considering that other categories are negligible in numbers, and that the legal framework discussed earlier focused on defamation specifically, @a16-mod-actions-by-country presents a breakdown by country, but specifically for illegal and harmful speech actions. This aligns with the court rulings presented earlier, which cite defamation, a form of harmful speech, as the primary mechanism for contestation.

@a16-mod-actions-by-country reveals a striking geographic concentration. Germany by itself represented 99.97% of all jurisdiction-specific actions filed under Article 16 for illegal and harmful speech, with 1,512,700 total moderation actions. To contextualize this concentration: France, the second-highest country by action volume, recorded 101 actions. Spain recorded 99, Poland 74, and Austria 49. All remaining EU countries combined account for fewer than 91 #footnote[Jurisdiction-specific actions only. There are up to 25 multi-jurisdiction actions in the study period, meaning they may cover multiple countries simultaneously] actions. Germany's volume exceeds France by a factor of approximately 15,000, a difference of roughly four orders of magnitude. This is not a proportional difference that might reflect market size or population; it is a categorical difference in moderation action activity. Spain, with 49 million inhabitants @instituto_nacional_de_estadistica_inebase_2025 and a mature digital economy, recorded 99 actions in the same period during which Germany recorded over 1.5 million. Poland, with 38 million inhabitants @statistics_poland_statistics_2025, recorded 74. Even Austria, which shares linguistic traditions with Germany, recorded only 49 actions.
The magnitude of this disparity eliminates the need for normalization or per-capita adjustment to establish disproportionality. When one jurisdiction accounts for 99.97% of a phenomenon while representing approximately 19% of EU #footnote[As of 1st of January 2025, computed from Eurostat data $83,577,140 slash 450,380,320 = 18.557%$ @eurostat_population_2025] population, no statistical correction is required to demonstrate that action activity does not track underlying market fundamentals. The difference is extreme both in absolute and relative terms.

@illegal-reason-breakdown breaks down the specific legal mechanism cited for actioning content deemed to constitute illegal or harmful speech. Of the 1,512,700 Germany-specific removals in this category, 1,512,595 (99.99%) cite defamation as the legal basis. Only 105 actions (0.01%) cite court orders as their removal mechanism. The transparency database does not specify what legal grounds these court orders invoke, making it unclear whether they represent defamation rulings, other personality-rights claims, or entirely different legal violations. Regardless, the distribution is unambiguous: defamation claims filed directly by businesses, rather than court-ordered removals, account for virtually all legal takedown activity on Google Maps in Germany.

To contextualize this concentration further, Germany's defamation-based removals can be expressed as a share of all Article 16 actions across the entire European Union. Recall from @mod-actions-by-cat that Article 16 actions totaled 1,514,957 across all legal categories and jurisdictions. Germany's 1,512,595 defamation removals therefore represent 99.84% of all legally-motivated content moderation actions on Google Maps EU-wide. In other words, nearly every legal complaint that prompts content removal on Google Maps anywhere in the European Union originates from Germany and invokes German defamation law.

=== Alternative Explanations

Several alternative explanations warrant consideration before attributing this 
concentration to institutional factors. The most fundamental challenge to any 
market-based explanation comes from platform incentive theory itself. @dellarocas_digitization_2003 established that reputation systems function only when consumers perceive aggregated feedback as trustworthy, platforms must moderate content to preserve system credibility. If the removed reviews were genuinely defamatory (fabricated by non-customers, containing false claims, or otherwise illegitimate), Google would have clear economic incentives to remove them everywhere, not just in Germany. Allowing fraudulent reviews to persist in France, Spain, or Poland would degrade platform trustworthiness and signal quality equally in those markets. The fact that removal activity concentrates almost exclusively in Germany (99.97%) while remaining negligible elsewhere therefore reveals that these are not responses to universally recognizable defamation. Instead, the pattern indicates that German legal framework reclassifies content as removable that platforms, and other jurisdictions, treat as legitimate consumer feedback. If review quality or authenticity drove removal decisions, the distribution would track review volumes and fraud rates across markets. The observed four order of magnitude concentration demonstrates that legal institutions, not content characteristics, determine removal outcomes.

=== Testing Hypothesis 1

H1 predicted that German businesses pursue systematic review suppression at scale on Google Maps. The data provide unambiguous support. Germany accounts for 99.84% of all Article 16 actions EU-wide, representing 1,512,595 defamation-based moderation actions during the 4.7-month study period. Because Article 16 actions are initiated exclusively through external legal complaints, this volume directly reflects business filing behavior. The concentration is systematic rather than occasional: 99.99% of actions use standardized direct defamation claims rather than court orders, indicating proceduralized suppression through platform complaint mechanisms. The pattern sustains consistently across the study period and exceeds comparable jurisdictions by four orders of magnitude. The alternative explanations analysis established that platform incentives would drive uniform removal of genuinely defamatory content @dellarocas_digitization_2003, yet removal concentrates exclusively in Germany, confirming that institutional factors, specifically, German court precedents lowering evidentiary thresholds and shifting verification burdens to platforms, enable suppression as routine business practice rather than exceptional legal remedy. H1 is supported.

== Success Rate of Removals

Large-scale removal activity demonstrates that businesses pursue suppression, but does not establish whether they can reliably expect success. If removal outcomes remain uncertain, suppression functions as a legal gamble rather than a dependable strategic tool. Analysis of complaint-level data from the Lumen Database reveals otherwise.

Of the 983 valid review URLs sampled from defamation-based takedown requests filed during October 1–20, 2025, 840 were confirmed removed at the time of verification on October 31. This yields a success rate of 85.45%, with a 95% confidence interval of [83.2%; 87.7%]. The lower bound of this interval substantially exceeds the 50% threshold specified in H2, indicating that businesses achieve removal in the overwhelming majority of cases when they contest reviews through defamation claims. The confidence interval [83.2%; 87.7%] deserves particular attention. Even at its lower bound, the success rate exceeds 83%, meaning that businesses can expect removal in more than four out of five attempts. The high success rate validates the theoretical prediction that platforms facing liability asymmetries will choose compliance over resistance. Google's self-reported median processing time for Article 16 notices is less than one day (Google, 2025b, § 2.4). The combination of 85% success rates and sub-24-hour processing indicates systematic approval of removal requests. This rapid, high-approval pattern is consistent with the institutional framework established earlier: when German court precedents place the burden of proving customer contact on platforms, and when data protection law prevents platforms from obtaining such evidence, compliance becomes the legally safer response than case-by-case adjudication. Whether Google actually conducts thorough verification remains unobservable from the available data, but the outcome pattern aligns with what economic theory predicts when one party can make claims that the other party cannot feasibly refute.

The procedural pathway through which businesses achieve these outcomes reinforces the interpretation that suppression operates systematically. Recall from Table 5 that 99.99% of German removals cite direct defamation claims rather than court orders. This means businesses achieve 85% success rates without obtaining judicial determinations first. They file complaints directly with Google through standardized Notice and Takedown forms, assert that reviews lack customer relationships or contain defamatory statements, and receive removal within one day in the median case. Courts function primarily as off-stage enforcers whose precedents shape platform behavior, but individual businesses need not engage the judicial system to achieve removal. This proceduralization is precisely what enables high success rates: platforms apply standards designed to minimize liability risk rather than adjudicating claims on their merits. The combination of high volume (H1) and high success rates (H2) together establish that suppressive reputation management functions as an institutionalized practice in Germany. Volume alone might reflect widespread filing of speculative complaints with low success rates. High success rates alone might reflect rare but meritorious cases where removal is clearly justified. The conjunction of both patterns indicates instead that businesses pursue suppression systematically because they can reliably expect compliance. This is the economic equilibrium predicted by the theoretical framework: when platforms face asymmetric liability and businesses face negligible costs, removal becomes routine.

=== Alternative Explanations

One alternative explanation warrants consideration: selection bias in complaint filing. If businesses only contest reviews when confident of success, the 85% success rate might reflect strategic case selection rather than permissive platform standards. Under this interpretation, high success rates indicate business restraint in filing only strong claims, not systematic platform compliance.

This explanation is difficult to reconcile with the volume findings from H1. If businesses exercised substantial restraint, removal volumes would approximate the actual incidence of fraudulent reviews. Instead, Germany exhibits 1.5 million removals in 4.7 months, volumes that exceed comparable markets by four orders of magnitude. Moreover, the existence and business model of Löschagenturen contradicts the restraint hypothesis: these agencies advertise fixed-price removal services for any unwanted review, not selective representation for clearly meritorious cases. The conjunction of extreme volume and high success rates indicates systematic approval rather than careful pre-filtering by businesses.

=== Testing Hypothesis 2

H2 predicted that review removal requests achieve reliably high success rates, operationalized as exceeding 50%. The Lumen Database analysis provides strong support. Of 983 sampled URLs from defamation-based takedown requests, 840 were confirmed removed, yielding a success rate of 85.45% with a 95% confidence interval of [83.2%; 87.7%]. The lower bound substantially exceeds the 50% threshold, confirming that businesses can reasonably expect removal when contesting reviews through defamation claims. When businesses in Germany contest reviews, removal is not merely a possible outcome but the expected outcome. The predictability of this process, evidenced by both high success rates and narrow confidence intervals, establishes that suppression functions as a dependable strategic tool rather than an uncertain legal remedy. H2 is supported.